import pandas
from googleapiclient.discovery import build
from multiprocessing.dummy import Pool as ThreadPool

url_id = ['ooWegesHKwY']

def croll_youtube(i):
    api_key = 'apií‚¤ë¥¼ ì…ë ¥í•˜ì‹œì˜¤ì˜¤'
    video_id = i
    comments = list()
    api_obj = build('youtube', 'v3', developerKey=api_key)
    response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, maxResults=100).execute()
    while response:
        for item in response['items']:
            if len(comments) >200:
                break
            comment = item['snippet']['topLevelComment']['snippet']
            comments.append([comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])
    
            if item['snippet']['totalReplyCount'] > 0:
                for reply_item in item['replies']['comments']:
                    reply = reply_item['snippet']
                    comments.append([reply['textDisplay'], reply['authorDisplayName'], reply['publishedAt'], reply['likeCount']])
    
        if 'nextPageToken' in response:
            response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()
        else:
            break
    df = pandas.DataFrame(comments)
    df[0] = df[0].str.replace('[^ã„±-ã… ã…-ã…£ ê°€-í£ ]','',regex=True)
    print(df[0])
    data_set = df[0].tolist()
    return data_set





pool = ThreadPool(12)

data_set = pool.map(croll_youtube,url_id)
pool.close()
pool.join()



from tensorflow.keras.models import load_model
import tensorflow as tf
import pickle
model = load_model('best_performed_model.h5')
print("âœ… ì „ì²´ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
# loading
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

def predict_text(model, tokenizer, text, maxlen=100):
    # 1ï¸âƒ£ ì…ë ¥ ë¬¸ì¥ì„ í† í°í™”í•˜ì—¬ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
    sequence = tokenizer.texts_to_sequences([text])

    # 2ï¸âƒ£ íŒ¨ë”© ì ìš© (ì…ë ¥ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´)
    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=maxlen)

    # 3ï¸âƒ£ ì˜ˆì¸¡ ìˆ˜í–‰
    prediction = model.predict(padded_sequence)

    # 4ï¸âƒ£ í™•ë¥ ì„ 0 ë˜ëŠ” 1ë¡œ ë³€í™˜
    label = (prediction > 0.5).astype(int)[0][0]

    # 5ï¸âƒ£ ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ”¹ ì…ë ¥ ë¬¸ì¥: {text}")
    print(f"ğŸ”¹ ì˜ˆì¸¡ëœ ë¼ë²¨: {label} (0: ë¶€ì •, 1: ê¸ì •)")
    print(f"ğŸ”¹ ì˜ˆì¸¡ëœ predict: {prediction} (0: ë¶€ì •, 1: ê¸ì •)")


from tensorflow.keras.models import load_model

# ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = load_model("best_performed_model.h5")

# ìƒˆë¡œìš´ ë¬¸ì¥ ì˜ˆì¸¡ ì˜ˆì œ
sample_text = data_set[0]
for i in sample_text:
    predict_text(model, tokenizer, i)